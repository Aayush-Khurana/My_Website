---
title: "Brexit results"
date: '2017-10-31T22:26:09-05:00'
description: Lorem Etiam Nullam
draft: no
image: pic09.jpg
keywords: ''
slug: brexit
categories:
- ''
- ''
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="where-do-people-drink-the-most-beer-wine-and-spirits" class="section level1">
<h1>Where Do People Drink The Most Beer, Wine And Spirits?</h1>
<p>Back in 2014, <a href="https://fivethirtyeight.com/features/dear-mona-followup-where-do-people-drink-the-most-beer-wine-and-spirits/">fivethiryeight.com</a> published an article on alchohol consumption in different countries. The data <code>drinks</code> is available as part of the <code>fivethirtyeight</code> package.</p>
<pre class="r"><code>library(fivethirtyeight)
data(drinks)</code></pre>
<p>Data Summary</p>
<pre class="r"><code># YOUR CODE GOES HERE

glimpse(drinks)</code></pre>
<pre><code>## Rows: 193
## Columns: 5
## $ country                      &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;And…
## $ beer_servings                &lt;int&gt; 0, 89, 25, 245, 217, 102, 193, 21, 261, 2…
## $ spirit_servings              &lt;int&gt; 0, 132, 0, 138, 57, 128, 25, 179, 72, 75,…
## $ wine_servings                &lt;int&gt; 0, 54, 14, 312, 45, 45, 221, 11, 212, 191…
## $ total_litres_of_pure_alcohol &lt;dbl&gt; 0.0, 4.9, 0.7, 12.4, 5.9, 4.9, 8.3, 3.8, …</code></pre>
<pre class="r"><code>skim(drinks)</code></pre>
<table>
<caption>(#tab:glimpse_skim_data)Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">drinks</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">193</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">country</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">28</td>
<td align="right">0</td>
<td align="right">193</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">beer_servings</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">106.16</td>
<td align="right">101.14</td>
<td align="right">0</td>
<td align="right">20.0</td>
<td align="right">76.0</td>
<td align="right">188.0</td>
<td align="right">376.0</td>
<td align="left">▇▃▂▂▁</td>
</tr>
<tr class="even">
<td align="left">spirit_servings</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">80.99</td>
<td align="right">88.28</td>
<td align="right">0</td>
<td align="right">4.0</td>
<td align="right">56.0</td>
<td align="right">128.0</td>
<td align="right">438.0</td>
<td align="left">▇▃▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">wine_servings</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">49.45</td>
<td align="right">79.70</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">8.0</td>
<td align="right">59.0</td>
<td align="right">370.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">total_litres_of_pure_alcohol</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4.72</td>
<td align="right">3.77</td>
<td align="right">0</td>
<td align="right">1.3</td>
<td align="right">4.2</td>
<td align="right">7.2</td>
<td align="right">14.4</td>
<td align="left">▇▃▅▃▁</td>
</tr>
</tbody>
</table>
<p>Top 25 beer consuming countries</p>
<pre class="r"><code>drinks %&gt;% slice_max(order_by = beer_servings, n=25)%&gt;% 
  ggplot(aes(x = beer_servings, y = fct_reorder(country, beer_servings)))+geom_col(fill = &quot;red&quot;) +
  theme_bw()+labs(
    title = &quot;top 25 beer consuming countries&quot;,
    subtitle = &quot;beer_servings&quot;,
    x = &quot;beer_servings&quot;,
    y = &quot;country&quot;
  )+
  NULL</code></pre>
<p><img src="/blogs/blog5_files/figure-html/beer_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Top 25 wine consuming countries</p>
<pre class="r"><code># YOUR CODE GOES HERE

drinks %&gt;% slice_max(order_by = wine_servings, n=25)%&gt;% 
  ggplot(aes(x = wine_servings, y = fct_reorder(country, wine_servings)))+geom_col(fill = &quot;blue&quot;) +
  theme_bw()+labs(
    title = &quot;top 25 wine consuming countries&quot;,
    subtitle = &quot;wine_servings&quot;,
    x = &quot;wine_servings&quot;,
    y = &quot;country&quot;
  )+
  NULL</code></pre>
<p><img src="/blogs/blog5_files/figure-html/wine_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Top 25 spirit consuming countries</p>
<pre class="r"><code># YOUR CODE GOES HERE

drinks %&gt;% slice_max(order_by = spirit_servings, n=25)%&gt;% 
  ggplot(aes(x = spirit_servings, y = fct_reorder(country, spirit_servings)))+geom_col(fill = &quot;green&quot;) +
  theme_bw()+labs(
    title = &quot;top 25 spirit consuming countries&quot;,
    subtitle = &quot;spirit_servings&quot;,
    x = &quot;spirit_servings&quot;,
    y = &quot;country&quot;
  )+
  NULL</code></pre>
<p><img src="/blogs/blog5_files/figure-html/spirit_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<blockquote>
<p>The dispersion in beer servings among countries is not as high as the one for wine or spirit-servings where highest consuming country is twice as higher as the lowest consuming country in the list. Beer consuming countries and wine countries share some overlaps. The top 25 spirit consuming countries are completely different from the previous two groups.</p>
</blockquote>
<blockquote>
<p>It is expected that beer and wine consumption are high in European countries as it can be cheaper and easier to buy in its origins. Spirits are consumed more in countries where there are social conventions or traditional occasions that require large consumption of spirits or countries that are located close to polar regions.</p>
</blockquote>
</div>
<div id="analysis-of-movies--imdb-dataset" class="section level1">
<h1>Analysis of movies- IMDB dataset</h1>
<p>We will look at a subset sample of movies, taken from the <a href="https://www.kaggle.com/carolzhangdc/imdb-5000-movie-dataset">Kaggle IMDB 5000 movie dataset</a></p>
<pre class="r"><code>movies &lt;- read_csv(here::here(&quot;data&quot;, &quot;movies.csv&quot;))
glimpse(movies)</code></pre>
<pre><code>## Rows: 2,961
## Columns: 11
## $ title               &lt;chr&gt; &quot;Avatar&quot;, &quot;Titanic&quot;, &quot;Jurassic World&quot;, &quot;The Avenge…
## $ genre               &lt;chr&gt; &quot;Action&quot;, &quot;Drama&quot;, &quot;Action&quot;, &quot;Action&quot;, &quot;Action&quot;, &quot;…
## $ director            &lt;chr&gt; &quot;James Cameron&quot;, &quot;James Cameron&quot;, &quot;Colin Trevorrow…
## $ year                &lt;dbl&gt; 2009, 1997, 2015, 2012, 2008, 1999, 1977, 2015, 20…
## $ duration            &lt;dbl&gt; 178, 194, 124, 173, 152, 136, 125, 141, 164, 93, 1…
## $ gross               &lt;dbl&gt; 7.61e+08, 6.59e+08, 6.52e+08, 6.23e+08, 5.33e+08, …
## $ budget              &lt;dbl&gt; 2.37e+08, 2.00e+08, 1.50e+08, 2.20e+08, 1.85e+08, …
## $ cast_facebook_likes &lt;dbl&gt; 4834, 45223, 8458, 87697, 57802, 37723, 13485, 920…
## $ votes               &lt;dbl&gt; 886204, 793059, 418214, 995415, 1676169, 534658, 9…
## $ reviews             &lt;dbl&gt; 3777, 2843, 1934, 2425, 5312, 3917, 1752, 1752, 35…
## $ rating              &lt;dbl&gt; 7.9, 7.7, 7.0, 8.1, 9.0, 6.5, 8.7, 7.5, 8.5, 7.2, …</code></pre>
<p>Besides the obvious variables of <code>title</code>, <code>genre</code>, <code>director</code>, <code>year</code>, and <code>duration</code>, the rest of the variables are as follows:</p>
<ul>
<li><code>gross</code> : The gross earnings in the US box office, not adjusted for inflation</li>
<li><code>budget</code>: The movie’s budget</li>
<li><code>cast_facebook_likes</code>: the number of facebook likes cast memebrs received</li>
<li><code>votes</code>: the number of people who voted for (or rated) the movie in IMDB</li>
<li><code>reviews</code>: the number of reviews for that movie</li>
<li><code>rating</code>: IMDB average rating</li>
</ul>
<div id="use-your-data-import-inspection-and-cleaning-skills-to-answer-the-following" class="section level2">
<h2>Use your data import, inspection, and cleaning skills to answer the following:</h2>
<ul>
<li>Are there any missing values (NAs)? Are all entries distinct or are there duplicate entries?</li>
</ul>
<pre class="r"><code>skim(movies)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-1">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">movies</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">2961</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">title</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">83</td>
<td align="right">0</td>
<td align="right">2907</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">genre</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">11</td>
<td align="right">0</td>
<td align="right">17</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">director</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">32</td>
<td align="right">0</td>
<td align="right">1366</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="18%" />
<col width="9%" />
<col width="12%" />
<col width="8%" />
<col width="8%" />
<col width="6%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">year</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.00e+03</td>
<td align="right">9.95e+00</td>
<td align="right">1920.0</td>
<td align="right">2.00e+03</td>
<td align="right">2.00e+03</td>
<td align="right">2.01e+03</td>
<td align="right">2.02e+03</td>
<td align="left">▁▁▁▂▇</td>
</tr>
<tr class="even">
<td align="left">duration</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.10e+02</td>
<td align="right">2.22e+01</td>
<td align="right">37.0</td>
<td align="right">9.50e+01</td>
<td align="right">1.06e+02</td>
<td align="right">1.19e+02</td>
<td align="right">3.30e+02</td>
<td align="left">▃▇▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">gross</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.81e+07</td>
<td align="right">7.25e+07</td>
<td align="right">703.0</td>
<td align="right">1.23e+07</td>
<td align="right">3.47e+07</td>
<td align="right">7.56e+07</td>
<td align="right">7.61e+08</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">budget</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4.06e+07</td>
<td align="right">4.37e+07</td>
<td align="right">218.0</td>
<td align="right">1.10e+07</td>
<td align="right">2.60e+07</td>
<td align="right">5.50e+07</td>
<td align="right">3.00e+08</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">cast_facebook_likes</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.24e+04</td>
<td align="right">2.05e+04</td>
<td align="right">0.0</td>
<td align="right">2.24e+03</td>
<td align="right">4.60e+03</td>
<td align="right">1.69e+04</td>
<td align="right">6.57e+05</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">votes</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.09e+05</td>
<td align="right">1.58e+05</td>
<td align="right">5.0</td>
<td align="right">1.99e+04</td>
<td align="right">5.57e+04</td>
<td align="right">1.33e+05</td>
<td align="right">1.69e+06</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">reviews</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.03e+02</td>
<td align="right">4.94e+02</td>
<td align="right">2.0</td>
<td align="right">1.99e+02</td>
<td align="right">3.64e+02</td>
<td align="right">6.31e+02</td>
<td align="right">5.31e+03</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">rating</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6.39e+00</td>
<td align="right">1.05e+00</td>
<td align="right">1.6</td>
<td align="right">5.80e+00</td>
<td align="right">6.50e+00</td>
<td align="right">7.10e+00</td>
<td align="right">9.30e+00</td>
<td align="left">▁▁▆▇▁</td>
</tr>
</tbody>
</table>
<pre class="r"><code>anyDuplicated(movies)</code></pre>
<pre><code>## [1] 0</code></pre>
<blockquote>
<p>No missing values or duplicates.</p>
</blockquote>
<ul>
<li>Produce a table with the count of movies by genre, ranked in descending order</li>
</ul>
<pre class="r"><code>movies %&gt;% 
  group_by(genre) %&gt;%
  summarise (count = n()) %&gt;%  
  arrange(desc(count)) </code></pre>
<pre><code>## # A tibble: 17 × 2
##    genre       count
##    &lt;chr&gt;       &lt;int&gt;
##  1 Comedy        848
##  2 Action        738
##  3 Drama         498
##  4 Adventure     288
##  5 Crime         202
##  6 Biography     135
##  7 Horror        131
##  8 Animation      35
##  9 Fantasy        28
## 10 Documentary    25
## 11 Mystery        16
## 12 Sci-Fi          7
## 13 Family          3
## 14 Musical         2
## 15 Romance         2
## 16 Western         2
## 17 Thriller        1</code></pre>
<ul>
<li>Produce a table with the average gross earning and budget (<code>gross</code> and <code>budget</code>) by genre. Calculate a variable <code>return_on_budget</code> which shows how many $ did a movie make at the box office for each $ of its budget. Ranked genres by this <code>return_on_budget</code> in descending order</li>
</ul>
<pre class="r"><code>movies %&gt;% 
  group_by(genre) %&gt;% 
  summarize(avg_gross = mean(gross),
            avg_budget=mean(gross/budget),
            return_on_budget=avg_gross/avg_budget) %&gt;% 
  arrange(desc(avg_gross))</code></pre>
<pre><code>## # A tibble: 17 × 4
##    genre        avg_gross avg_budget return_on_budget
##    &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;
##  1 Family      149160478.   14.1            10596426.
##  2 Animation    98433792.    5.01           19651012.
##  3 Adventure    95794257.    2.41           39720544.
##  4 Musical      92084000    18.8             4893447.
##  5 Action       86583860.    1.92           45075166.
##  6 Mystery      67533021.    3.27           20656108.
##  7 Biography    45201805.   22.3             2028752.
##  8 Comedy       42630552.    3.71           11478370.
##  9 Fantasy      42408841.    6.68            6346758.
## 10 Horror       37713738.   88.3              427086.
## 11 Crime        37502397.    2.17           17244453.
## 12 Drama        37465371.    2.95           12716917.
## 13 Romance      31264848.    3.17            9868607.
## 14 Sci-Fi       29788371.    1.58           18848695.
## 15 Western      20821884     7.06            2948106.
## 16 Documentary  17353973.    8.70            1995042.
## 17 Thriller         2468     0.00823          300000</code></pre>
<ul>
<li>Produce a table that shows the top 15 directors who have created the highest gross revenue in the box office. Don’t just show the total gross amount, but also the mean, median, and standard deviation per director.</li>
</ul>
<pre class="r"><code>movies %&gt;% 
  group_by(director) %&gt;%  
  summarize(total_gross = sum(gross),
            avg_gross=mean(gross),max_gross=max(gross),
            med_gross = median(gross), 
            sd_gross = sd(gross)) %&gt;% 
  arrange(desc(total_gross)) %&gt;% 
  slice_max(order_by = total_gross, n=15) </code></pre>
<pre><code>## # A tibble: 15 × 6
##    director          total_gross  avg_gross max_gross  med_gross   sd_gross
##    &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1 Steven Spielberg   4014061704 174524422. 434949459 164435221  101421051.
##  2 Michael Bay        2231242537 171634041. 402076689 138396624  127161579.
##  3 Tim Burton         2071275480 129454718. 334185206  76519172  108726924.
##  4 Sam Raimi          2014600898 201460090. 403706375 234903076  162126632.
##  5 James Cameron      1909725910 318287652. 760505847 175562880. 309171337.
##  6 Christopher Nolan  1813227576 226653447  533316061 196667606. 187224133.
##  7 George Lucas       1741418480 348283696  474544677 380262555  146193880.
##  8 Robert Zemeckis    1619309108 124562239. 329691196 100853835   91300279.
##  9 Clint Eastwood     1378321100  72543216. 350123553  46700000   75487408.
## 10 Francis Lawrence   1358501971 271700394. 424645577 281666058  135437020.
## 11 Ron Howard         1335988092 111332341  260031035 101587923   81933761.
## 12 Gore Verbinski     1329600995 189942999. 423032628 123207194  154473822.
## 13 Andrew Adamson     1137446920 284361730  436471036 279680930. 120895765.
## 14 Shawn Levy         1129750988 102704635. 250863268  85463309   65484773.
## 15 Ridley Scott       1128857598  80632686. 228430993  47775715   68812285.</code></pre>
<ul>
<li>Finally, ratings. Produce a table that describes how ratings are distributed by genre.</li>
</ul>
<pre class="r"><code>movies %&gt;% 
  group_by(genre) %&gt;%
  summarize(
            avg_rating=mean(rating),
            med_rating = median(rating),
            max_rating=max(rating),
            min_rating = min(rating), 
            sd_rating = sd(rating)) </code></pre>
<pre><code>## # A tibble: 17 × 6
##    genre       avg_rating med_rating max_rating min_rating sd_rating
##    &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;
##  1 Action            6.23       6.3         9          2.1     1.03 
##  2 Adventure         6.51       6.6         8.6        2.3     1.09 
##  3 Animation         6.65       6.9         8          4.5     0.968
##  4 Biography         7.11       7.2         8.9        4.5     0.760
##  5 Comedy            6.11       6.2         8.8        1.9     1.02 
##  6 Crime             6.92       6.9         9.3        4.8     0.849
##  7 Documentary       6.66       7.4         8.5        1.6     1.77 
##  8 Drama             6.73       6.8         8.8        2.1     0.917
##  9 Family            6.5        5.9         7.9        5.7     1.22 
## 10 Fantasy           6.15       6.45        7.9        4.3     0.959
## 11 Horror            5.83       5.9         8.5        3.6     1.01 
## 12 Musical           6.75       6.75        7.2        6.3     0.636
## 13 Mystery           6.86       6.9         8.5        4.6     0.882
## 14 Romance           6.65       6.65        7.1        6.2     0.636
## 15 Sci-Fi            6.66       6.4         8.2        5       1.09 
## 16 Thriller          4.8        4.8         4.8        4.8    NA    
## 17 Western           5.7        5.7         7.3        4.1     2.26</code></pre>
<pre class="r"><code>ggplot(data=movies, aes(x=rating, group=genre, fill=genre)) +
    geom_density(adjust=1.5, alpha=.4) +
    facet_wrap(~genre) +
    theme(
      legend.position=&quot;none&quot;,
      panel.spacing = unit(0.1, &quot;lines&quot;),
      axis.ticks.x=element_blank()
    )</code></pre>
<p><img src="/blogs/blog5_files/figure-html/unnamed-chunk-5-1.png" width="648" style="display: block; margin: auto;" />
&gt; Ratings vary more for Documentary, Family, Fantasy, Sci-Fi and Western movie genres, and ratings seem to be similar for Romance, Musical, Mystery and Biography movie genres.</p>
</div>
<div id="use-ggplot-to-answer-the-following" class="section level2">
<h2>Use <code>ggplot</code> to answer the following</h2>
<ul>
<li>Examine the relationship between <code>gross</code> and <code>cast_facebook_likes</code>.</li>
</ul>
<pre class="r"><code>ggplot(movies, aes(x=cast_facebook_likes, 
                        y=gross)) +
    geom_point()+
  geom_smooth(
  method=lm  
  )+
labs(
        x = &quot;facebook likes&quot;,
        y = &quot;gross&quot;,
        color = &quot;Gear&quot;,
        title = &quot;Relationship between facebook likes and gross earnings&quot;
    )</code></pre>
<p><img src="/blogs/blog5_files/figure-html/gross_on_fblikes-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary(lm(gross ~ cast_facebook_likes, data=movies))</code></pre>
<pre><code>## 
## Call:
## lm(formula = gross ~ cast_facebook_likes, data = movies)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -4.59e+08 -4.35e+07 -2.23e+07  1.76e+07  7.08e+08 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         4.88e+07   1.52e+06    32.1   &lt;2e-16 ***
## cast_facebook_likes 7.52e+02   6.34e+01    11.9   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 70800000 on 2959 degrees of freedom
## Multiple R-squared:  0.0454, Adjusted R-squared:  0.0451 
## F-statistic:  141 on 1 and 2959 DF,  p-value: &lt;2e-16</code></pre>
<blockquote>
<p>The trend line suggests positive relationship between facebook likes and gross earnings of a movie. Hence facebook likes of the cast can be good predictor of how much money a movie will make at the box office.</p>
</blockquote>
<ul>
<li>Examine the relationship between <code>gross</code> and <code>budget</code>.</li>
</ul>
<pre class="r"><code>ggplot(movies, aes(x=budget, 
                        y=gross)) +
geom_point()+
  geom_smooth(
  method=lm  
  )+
labs(
        x = &quot;budget&quot;,
        y = &quot;gross&quot;,
        color = &quot;Gear&quot;,
        title = &quot;Relationship between budget and gross earnings&quot;,
    )</code></pre>
<p><img src="/blogs/blog5_files/figure-html/gross_on_budget-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary(lm(gross ~ budget, data=movies))</code></pre>
<pre><code>## 
## Call:
## lm(formula = gross ~ budget, data = movies)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -2.22e+08 -2.60e+07 -1.24e+07  1.31e+07  4.94e+08 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 1.49e+07   1.40e+06    10.7   &lt;2e-16 ***
## budget      1.06e+00   2.34e-02    45.4   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 55600000 on 2959 degrees of freedom
## Multiple R-squared:  0.411,  Adjusted R-squared:  0.41 
## F-statistic: 2.06e+03 on 1 and 2959 DF,  p-value: &lt;2e-16</code></pre>
<blockquote>
<p>This plot shows the relationship between gross and budget much better than the previous one with facebook likes. Also the p-values let one assume a high significance in the positive relationship.</p>
</blockquote>
<ul>
<li>Examine the relationship between <code>gross</code> and <code>rating</code>.</li>
</ul>
<pre class="r"><code>ggplot(movies, aes(x = rating, y = gross)) +
    geom_point() +
  facet_wrap(~ genre) +
  geom_smooth(method=lm) +
      labs(
        x = &quot;rating&quot;,
        y = &quot;gross&quot;,
        color = &quot;Gear&quot;,
        title = &quot;gross_on_rating&quot;,
    )</code></pre>
<p><img src="/blogs/blog5_files/figure-html/gross_on_rating-1.png" width="648" style="display: block; margin: auto;" />
&gt; There is generally a positive relationship between gross and rating for most movie genres as one would assume except for documentaries and Sci-Fi, which seem to have a worse rating for higher gross movies. But, it is also worth noting that for some genres, such as Musical, Family, Romance, Thriller and Western, there is not enough data as to come with a conclusion.</p>
</div>
</div>
<div id="returns-of-financial-stocks" class="section level1">
<h1>Returns of financial stocks</h1>
<blockquote>
<p>You may find useful the material on <a href="https://mfa2022.netlify.app/reference/finance_data/">finance data sources</a>.</p>
</blockquote>
<p>We will use the <code>tidyquant</code> package to download historical data of stock prices, calculate returns, and examine the distribution of returns.</p>
<p>(Apple is known as AAPL, Microsoft as MSFT, McDonald’s as MCD, etc. The file <code>nyse.csv</code> contains 508 stocks listed on the NYSE, their ticker <code>symbol</code>, <code>name</code>, the IPO (Initial Public Offering) year, and the sector and industry the company is in.)</p>
<pre class="r"><code>library(tidyquant)
nyse &lt;- read_csv(here::here(&quot;data&quot;,&quot;nyse.csv&quot;))</code></pre>
<p>Based on this dataset, create a table and a bar plot that shows the number of companies per sector, in descending order.</p>
<pre class="r"><code># table
nyse %&gt;% 
  group_by(sector) %&gt;% 
   count(sort=TRUE) </code></pre>
<pre><code>## # A tibble: 12 × 2
## # Groups:   sector [12]
##    sector                    n
##    &lt;chr&gt;                 &lt;int&gt;
##  1 Finance                  97
##  2 Consumer Services        79
##  3 Public Utilities         60
##  4 Capital Goods            45
##  5 Health Care              45
##  6 Energy                   42
##  7 Technology               40
##  8 Basic Industries         39
##  9 Consumer Non-Durables    31
## 10 Miscellaneous            12
## 11 Transportation           10
## 12 Consumer Durables         8</code></pre>
<pre class="r"><code># bar plot
nyse %&gt;%
  mutate(sector = fct_rev(fct_infreq(sector)))%&gt;%
  ggplot(aes(y=sector))+
  geom_bar()+
  labs(
    title = &quot;Number of companies per sector&quot;,
    subtitle = &quot;Based on 508 stocks listed on the NYSE&quot;,
    x = &quot;Count&quot;,
    y=&quot;Sector&quot;
    )</code></pre>
<p><img src="/blogs/blog5_files/figure-html/companies_per_sector-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Next, let’s choose the <a href="https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average">Dow Jones Industrial Aveareg (DJIA)</a> stocks and their ticker symbols and download some data. Besides the 30 stocks that make up the DJIA, we will also add <code>SPY</code> which is an SP500 ETF (Exchange Traded Fund).</p>
<pre class="r"><code>djia_url &lt;- &quot;https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average&quot;


#get tables that exist on URL
tables &lt;- djia_url %&gt;% 
  read_html() %&gt;% 
  html_nodes(css=&quot;table&quot;)


# parse HTML tables into a dataframe called djia. 
# Use purr::map() to create a list of all tables in URL
djia &lt;- map(tables, . %&gt;% 
               html_table(fill=TRUE)%&gt;% 
               clean_names())


# constituents
table1 &lt;- djia[[2]] %&gt;% # the second table on the page contains the ticker symbols
  mutate(date_added = ymd(date_added),
         
         # if a stock is listed on NYSE, its symbol is, e.g., NYSE: MMM
         # We will get prices from yahoo finance which requires just the ticker
         
         # if symbol contains &quot;NYSE*&quot;, the * being a wildcard
         # then we jsut drop the first 6 characters in that string
         ticker = ifelse(str_detect(symbol, &quot;NYSE*&quot;),
                          str_sub(symbol,7,11),
                          symbol)
         )

# we need a vector of strings with just the 30 tickers + SPY
tickers &lt;- table1 %&gt;% 
  select(ticker) %&gt;% 
  pull() %&gt;% # pull() gets them as a sting of characters
  c(&quot;SPY&quot;) # and lets us add SPY, the SP500 ETF</code></pre>
<p>Now let us downlaod prices for all 30 DJIA consituents and the SPY ETF that tracks SP500 since January 1, 2020</p>
<pre class="r"><code># Notice the cache=TRUE argument in the chunk options. Because getting data is time consuming, # cache=TRUE means that once it downloads data, the chunk will not run again next time you knit your Rmd

myStocks &lt;- tickers %&gt;% 
  tq_get(get  = &quot;stock.prices&quot;,
         from = &quot;2000-01-01&quot;,
         to   = Sys.Date()) %&gt;% # Sys.Date() returns today&#39;s price
  group_by(symbol) 

glimpse(myStocks) # examine the structure of the resulting data frame</code></pre>
<pre><code>## Rows: 162,018
## Columns: 8
## Groups: symbol [31]
## $ symbol   &lt;chr&gt; &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;…
## $ date     &lt;date&gt; 2000-01-03, 2000-01-04, 2000-01-05, 2000-01-06, 2000-01-07, …
## $ open     &lt;dbl&gt; 48.0, 46.4, 45.6, 47.2, 50.6, 50.2, 50.4, 51.0, 50.7, 50.4, 4…
## $ high     &lt;dbl&gt; 48.2, 47.4, 48.1, 51.2, 51.9, 51.8, 51.2, 51.8, 50.9, 50.5, 4…
## $ low      &lt;dbl&gt; 47.0, 45.3, 45.6, 47.2, 50.0, 50.0, 50.2, 50.4, 50.2, 49.5, 4…
## $ close    &lt;dbl&gt; 47.2, 45.3, 46.6, 50.4, 51.4, 51.1, 50.2, 50.4, 50.4, 49.7, 4…
## $ volume   &lt;dbl&gt; 2173400, 2713800, 3699400, 5975800, 4101200, 3863800, 2357600…
## $ adjusted &lt;dbl&gt; 27.2, 26.1, 26.9, 29.0, 29.6, 29.4, 28.9, 29.0, 29.0, 28.6, 2…</code></pre>
<p>Financial performance analysis depend on returns; If I buy a stock today for 100 and I sell it tomorrow for 101.75, my one-day return, assuming no transaction costs, is 1.75%. So given the adjusted closing prices, our first step is to calculate daily and monthly returns.</p>
<p>Financial performance analysis depend on returns; If I buy a stock today for 100 and I sell it tomorrow for 101.75, my one-day return, assuming no transaction costs, is 1.75%. So given the adjusted closing prices, our first step is to calculate daily and monthly returns.</p>
<pre class="r"><code>#calculate daily returns
myStocks_returns_daily &lt;- myStocks %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;daily&quot;, 
               type       = &quot;log&quot;,
               col_rename = &quot;daily_returns&quot;,
               cols = c(nested.col))  

#calculate monthly  returns
myStocks_returns_monthly &lt;- myStocks %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;monthly&quot;, 
               type       = &quot;arithmetic&quot;,
               col_rename = &quot;monthly_returns&quot;,
               cols = c(nested.col)) 

#calculate yearly returns
myStocks_returns_annual &lt;- myStocks %&gt;%
  group_by(symbol) %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;yearly&quot;, 
               type       = &quot;arithmetic&quot;,
               col_rename = &quot;yearly_returns&quot;,
               cols = c(nested.col))</code></pre>
<p>Produce a table that summarizes monthly returns for each of the stocks and <code>SPY</code>; min, max, median, mean, SD.</p>
<pre class="r"><code># YOUR CODE GOES HERE

p1 = myStocks_returns_monthly %&gt;% 
  group_by(symbol) %&gt;% 
  summarize(min=min(monthly_returns),
         max = max(monthly_returns),
         median = median(monthly_returns),
         mean = mean(monthly_returns),
         sd = sd(monthly_returns))
p1</code></pre>
<pre><code>## # A tibble: 31 × 6
##    symbol    min   max  median    mean     sd
##    &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
##  1 AAPL   -0.577 0.454 0.0352  0.0269  0.115 
##  2 AMGN   -0.170 0.328 0.00856 0.00811 0.0732
##  3 AXP    -0.279 0.875 0.0109  0.0101  0.0921
##  4 BA     -0.458 0.459 0.0165  0.0126  0.0925
##  5 CAT    -0.353 0.350 0.0141  0.0144  0.0898
##  6 CRM    -0.360 0.403 0.0205  0.0262  0.110 
##  7 CSCO   -0.367 0.389 0.0125  0.00606 0.0962
##  8 CVX    -0.224 0.273 0.0108  0.00891 0.0654
##  9 DIS    -0.268 0.234 0.0100  0.0104  0.0737
## 10 DOW    -0.276 0.255 0.0325  0.0156  0.109 
## # … with 21 more rows</code></pre>
<p>Plot a density plot, using <code>geom_density()</code>, for each of the stocks</p>
<pre class="r"><code># YOUR CODE GOES HERE
myStocks_returns_monthly %&gt;% 
ggplot(aes(x = monthly_returns, color = symbol))+ 
  geom_density()+
  facet_wrap(vars(symbol))+
  labs(
    title = &quot;Monthly Returns&quot;,
    subtitle = &quot;Based on 30 DJIA consituents and SPY ETF&quot;,
    x = &quot;Monthly Return&quot;,
    y=&quot;Company Ticker&quot;)</code></pre>
<p><img src="/blogs/blog5_files/figure-html/density_monthly_returns-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>What can you infer from this plot? Which stock is the riskiest? The least risky?</p>
<blockquote>
<p>Riskiness can be interpreted as the variance of stock returns. The density plots suggests that Apple is the riskiest stock as the dispersion of its monthly returns seems to be the largest. SPY index and Microsoft or the S&amp;P 500 seem to be the least risky one as most data concentrate around the mean with very little variance.</p>
</blockquote>
<p>Finally, make a plot that shows the expected monthly return (mean) of a stock on the Y axis and the risk (standard deviation) in the X-axis. Please use <code>ggrepel::geom_text_repel()</code> to label each stock</p>
<pre class="r"><code># YOUR CODE GOES HERE
ggplot(p1, aes(x=sd, y=mean, label=symbol))+
  geom_point()+
  ggrepel::geom_text_repel()+
  labs(
    title = &quot;Expected monthly return vs risk&quot;,
    x = &quot;Risk&quot;,
    y=&quot;Expected return&quot;)+
  geom_smooth(method = lm)</code></pre>
<p><img src="/blogs/blog5_files/figure-html/risk_return_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>What can you infer from this plot? Are there any stocks which, while being riskier, do not have a higher expected return?</p>
<blockquote>
<p>There is generally a positive relationship between risk and expected return. There are some that are riskier for the return that they generate. Examples would be INTC and CSCO.</p>
</blockquote>
</div>
<div id="is-inflation-transitory" class="section level1">
<h1>Is inflation transitory?</h1>
<blockquote>
<p>You may find useful the material on <a href="https://mfa2022.netlify.app/reference/finance_data/#data-from-the-federal-reserve-economic-data-with-tidyquant">downloading economic data from the FRED</a>.</p>
</blockquote>
<p>A recent study by the Bank for International Settlements (BIS) claimed that the <a href="https://www.bloomberg.com/news/articles/2021-09-20/current-inflation-spike-is-just-transitory-new-bis-study-argues">Current Inflation Spike Is Just Transitory</a>. As the article says,</p>
<blockquote>
<p>The surge in inflation seen across major economies is probably short lived because it’s confined to just a few sectors of the economy, according to the Bank for International Settlements.</p>
</blockquote>
<blockquote>
<p>New research by the BIS’s Claudio Borio, Piti Disyatat, Egon Zakrajsek and Dora Xia adds to one of the hottest debates in economics – how long the current surge in consumer prices will last. Both Federal Reserve Chair Jerome Powell and his euro-area counterpart Christine Lagarde have said the pickup is probably transitory, despite a snarled global supply chain and a spike in energy prices.</p>
</blockquote>
<p>You have to download data for CPI and the 10 year bill and produce the following graph</p>
<p><img src="/Users/aayushkhurana/Desktop/London Business School/Data analytics for Finance/My_Website/ca09.mfa2022/images/cpi_10year.png" width="90%" style="display: block; margin: auto;" /></p>
<p>The relevant indicators from FRED are:</p>
<ul>
<li><a href="https://fred.stlouisfed.org/series/CPIAUCSL">Consumer Price Index for All Urban Consumers: All Items in U.S. City Average</a></li>
<li><a href="https://fred.stlouisfed.org/series/GS10">10-Year Treasury Constant Maturity Rate</a></li>
</ul>
<pre class="r"><code>cpi  &lt;-   tq_get(&quot;CPIAUCSL&quot;, get = &quot;economic.data&quot;,
                       from = &quot;1980-01-01&quot;) %&gt;% 
  rename(cpi = symbol,  # FRED data is given as &#39;symbol&#39; and &#39;price&#39;
         rate = price) %&gt;% # we rename them to what they really are, e.g., cpi and rate
  
  # calculate yearly change in CPI by dividing current month by same month a year (or 12 months) earlier, minus 1
  mutate(cpi_yoy_change = rate/lag(rate, 12) - 1)

ten_year_monthly  &lt;-   tq_get(&quot;GS10&quot;, get = &quot;economic.data&quot;,
                       from = &quot;1980-01-01&quot;) %&gt;% 
  rename(ten_year = symbol,
         yield = price) %&gt;% 
  mutate(yield = yield / 100) # original data is not given as, e.g., 0.05, but rather 5, for five percent

# we have the two dataframes-- we now need to join them, and we will use left_join()
# base R has a function merge() that does the same, but it&#39;s slow, so please don&#39;t use it

mydata &lt;- 
  cpi %&gt;% 
  left_join(ten_year_monthly, by=&quot;date&quot;) %&gt;% 
  mutate(
    year = year(date), # using lubridate::year() to generate a new column with just the year
    month = month(date),
    decade=case_when(
      year %in% 1980:1989 ~ &quot;1980s&quot;,
      year %in% 1990:1999 ~ &quot;1990s&quot;,
      year %in% 2000:2009 ~ &quot;2000s&quot;,
      year %in% 2010:2019 ~ &quot;2010s&quot;,
      TRUE ~ &quot;2020s&quot;
      )
  )</code></pre>
<pre class="r"><code>ggplot(mydata, aes(x=cpi_yoy_change, y=rate/1000, color=decade, label=paste(mydata$month, mydata$year, sep=&quot; &quot;))) +
  geom_point() +
  geom_smooth(method=&quot;lm&quot;, se=F) +
  facet_wrap(~decade, ncol=1) +
  labs(x=&quot;CPI Yearly Change&quot;,
       y= &quot;10-Year Treasury Constant Maturity Rate&quot;,
       title=&quot;How are CPI and 10-year yield related?&quot;) +
  theme_bw() +
  scale_y_continuous(labels = percent) +
  scale_x_continuous(labels = percent) +
  labs(color=&quot;Decade&quot;) +
  ggrepel::geom_text_repel()</code></pre>
<p><img src="/blogs/blog5_files/figure-html/unnamed-chunk-6-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="challenge-2-opinion-polls-for-the-2021-german-elections" class="section level1">
<h1>Challenge 2: Opinion polls for the 2021 German elections</h1>
<p>The Guardian newspaper has an <a href="https://www.theguardian.com/world/2021/aug/20/german-election-poll-tracker-who-will-be-the-next-chancellor">election poll tracker for the upcoming German election</a>.
The list of the opinion polls since Jan 2021 can be found at <a href="https://en.wikipedia.org/wiki/Opinion_polling_for_the_2021_German_federal_election">Wikipedia</a> and your task is to reproduce the graph similar to the one produced by the Guardian.</p>
<p>The following code will scrape the wikipedia page and import the table in a dataframe.</p>
<pre class="r"><code>url &lt;- &quot;https://en.wikipedia.org/wiki/Opinion_polling_for_the_2021_German_federal_election&quot;

# similar graphs and analyses can be found at 
# https://www.theguardian.com/world/2021/jun/21/german-election-poll-tracker-who-will-be-the-next-chancellor
# https://www.economist.com/graphic-detail/who-will-succeed-angela-merkel


# get tables that exist on wikipedia page 
tables &lt;- url %&gt;% 
  read_html() %&gt;% 
  html_nodes(css=&quot;table&quot;)


# parse HTML tables into a dataframe called polls 
# Use purr::map() to create a list of all tables in URL
polls &lt;- map(tables, . %&gt;% 
             html_table(fill=TRUE)%&gt;% 
             janitor::clean_names())


# list of opinion polls
german_election_polls &lt;- polls[[1]] %&gt;% # the first table on the page contains the list of all opinions polls
  slice(2:(n()-1)) %&gt;%  # drop the first row, as it contains again the variable names and last row that contains 2017 results
  mutate(
         # polls are shown to run from-to, e.g. 9-13 Aug 2021. We keep the last date, 13 Aug here, as the poll date
         # and we extract it by picking the last 11 characters from that field
         end_date = str_sub(fieldwork_date, -11),
         
         # end_date is still a string, so we convert it into a date object using lubridate::dmy()
         end_date = dmy(end_date),
         
         # we also get the month and week number from the date, if we want to do analysis by month- week, etc.
         month = month(end_date),
         week = isoweek(end_date)
         )


colors &lt;- c(&quot;SPD&quot; = &quot;red&quot;,
            &quot;AFD&quot; = &quot;blue&quot;,
            &quot;CDU/CSU&quot; = &quot;black&quot;,
            &quot;Grüne&quot; = &quot;green&quot;,
            &quot;FDP&quot; = &quot;yellow&quot;,
            &quot;Linke&quot; = &quot;purple&quot;)

ggplot(german_election_polls, aes(x=end_date)) +
  geom_point(alpha=0.3, aes(y=spd, color=&quot;SPD&quot;)) +
  geom_line(alpha=0.5, aes(y=rollmean(spd, 14, na.pad=TRUE), color=&quot;SPD&quot;)) +
  geom_point(alpha=0.3, aes(y=af_d, color = &quot;AFD&quot;)) +
  geom_line(alpha=0.5, aes(y=rollmean(af_d, 14, na.pad=TRUE), color = &quot;AFD&quot;)) +
  geom_point(alpha=0.3, aes(y=union, color = &quot;CDU/CSU&quot;)) +
  geom_line(alpha=0.5, aes(y=rollmean(union, 14, na.pad=TRUE), color = &quot;CDU/CSU&quot;)) +
  geom_point(alpha=0.3, aes(y=grune, color = &quot;Grüne&quot;)) +
  geom_line(alpha=0.5, aes(y=rollmean(grune, 14, na.pad=TRUE), color = &quot;Grüne&quot;)) +
  geom_point(alpha=0.3, aes(y=fdp, color = &quot;FDP&quot;)) +
  geom_line(alpha=0.5, aes(y=rollmean(fdp, 14, na.pad=TRUE), color = &quot;FDP&quot;)) +
  geom_point(alpha=0.3, aes(y=linke, color = &quot;Linke&quot;)) +
  geom_line(alpha=0.5, aes(y=rollmean(linke, 14, na.pad=TRUE), color = &quot;Linke&quot;)) +
  labs(x = &quot;Time&quot;,
         y = &quot;Percentage&quot;,
       color = &quot;Parties&quot;,
       title = &quot;Uncertainty is challenging&quot;,
       subtitle = &quot;14-day rolling average for election polls&quot;) +
  theme(legend.position=&quot;right&quot;) +
  scale_color_manual(values = colors)</code></pre>
<p><img src="/blogs/blog5_files/figure-html/scrape_wikipedia_polling_data-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
